#HTML 

- Even though HTML looks like XML and some pages are carefully constructed to be XML, most HTML is generally broken in ways that cause an XML parser to reject the entire page of HTML as improperly formed.
- There are a number of Python libraries which can help you parse HTML and extract data from the pages.
- BeautifulSoup is one we will use and a popular one at that.
- BeautifulSoup tolerates highly flawed HTML and still lets you easily extract the data you need.
- To install BeautifulSoup with conda the command is:
```python
conda install -c anaconda beautifulsoup4
```

- We will use `bs4` to parse HTML input and extract links from.

We will use `urllib` to read and then use `BeautifulSoup` to extract `href` attributes from the anchor (a) tags.
```python
# To run this, download the BeautifulSoup zip file  
# http://www.py4e.com/code3/bs4.zip  
# and unzip it in the same directory as this file
  
import urllib.request, urllib.parse, urllib.error  
from bs4 import BeautifulSoup  
import ssl  

# Ignore SSL certificate errors  
ctx = ssl.create_default_context()  
ctx.check_hostname = False  
ctx.verify_mode = ssl.CERT_NONE  

url = input('Enter - ')  
html = urllib.request.urlopen(url, context=ctx).read() 
soup = BeautifulSoup(html, 'html.parser')  

# Retrieve all of the anchor tags  
tags = soup('a')  
for tag in tags:  
    print(tag.get('href', None))
```
- The program prompts for a web address, then opens the web page,
- Reads the data and passes the data to the BeautifulSoup parser,
- Then retrieves all of the anchor tags and prints out the `href` attribute for each tag.
`Out:`
```
Enter - https://docs.python.org
genindex.html
py-modindex.html
https://www.python.org/
#
whatsnew/3.6.html
whatsnew/index.html
tutorial/index.html
library/index.html
reference/index.html
using/index.html
howto/index.html
installing/index.html
distributing/index.html
extending/index.html
c-api/index.html
faq/index.html
py-modindex.html
genindex.html
glossary.html
search.html
contents.html
bugs.html
about.html
license.html
copyright.html
download.html
...
```
- This list is much longer because some HTML anchor tags are relative paths (e.g., ` tutorial/index.html`)
- Or in-page references (e.g.,'#') that do not include "http://" or "https://", which was required by our regex.

You can use `bs4` to pull out various parts of each tag:
```python
from urllib.request import urlopen
from bs4 import BeautifulSoup
import ssl

# Ignore SSL certificate errors
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

url = input('Enter - ')
html = urlopen(url, context=ctx).read()
soup = BeautifulSoup(html, "html.parser")

# Retrieve all of the anchor tags
tags = soup('a')
for tag in tags:
    # Look at the parts of a tag
    print('TAG:', tag)
    print('URL:', tag.get('href', None))
    print('Contents:', tag.contents[0])
    print('Attrs:', tag.attrs)
```
`Out:`
```
Enter - http://www.dr-chuck.com/page1.htm
TAG: <a href="http://www.dr-chuck.com/page2.htm">
Second Page</a>
URL: http://www.dr-chuck.com/page2.htm
Contents: 
Second Page
Attrs: {'href': 'http://www.dr-chuck.com/page2.htm'}
```

- `html.parser` is the HTML parser included in the standard Python 3 library.
